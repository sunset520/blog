---
title: "概率论"
categories:
    - 概统
image: "image.jpg"
---

# 概率论

## 概率论的基本概念

### 随机试验，样本空间，随机事件

随机试验：满足相同条件下可重复，能事先明确试验所有可能结果，在一次试验前无法确定哪一个结果出现的试验称为随机试验。

样本空间：将随机试验 $E$ 的所有可能结果组成的集合称为 $E$ 的样本空间。$E$ 的每个结果称为样本点。

随机事件：称试验 $E$ 的样本空间 $S$ 的子集为 $E$ 的随机事件。

和事件，积事件，差时间，互斥事件与对立事件

交换律，结合律，分配律，德摩根律

### 频率与概率

频率：相同条件下，进行了 $n$ 次试验，事件 $A$ 发生的次数 $n _ A$ 称为事件 $A$ 发生的频数，比值 $\frac{n _ A}{n}$ 称为事件 $A$ 发生的频率，记为 $f _ {n}(A)$。

概率：设 $E$ 是随机事件，$S$ 是它的样本空间。对于 $E$ 的每一个事件 $A$ 赋予一个实数，记为 $P(A)$，称为事件 $A$ 的概率，如果集合函数 $P(\cdot)$ 满足以下条件：

（1）非负性：对于每个事件 $A$，有 $P(A)\geq 0$。

（2）规范性：对于必然事件 $S$，有 $P(S)=1$。

（3）可列可加性：设 $A _ 1,A _ 2,\cdots$ 是两两不相容的事件，即对于 $A _ {i}A _ {j}=\emptyset ,i\neq j,i,j=1,2,\cdots$，有

$$
P(A _ 1\cup A _ 2\cup \cdots)=P(A _ 1)+P(A _ 2)+\cdots
$$

加法公式：对于任意两事件 $A,B$ 有

$$
P(A\cup B)=P(A)+P(B)-P(AB)
$$

### 古典概型

当随机试验满足样本空间内只有有限个元素，且每个基本事件发生的可能性相同，则称为等可能概型，又称古典概型。

超几何分布

### 条件概率

条件概率：设 $A,B$ 是两个事件，且 $P(A)>0$，称

$$
P(B|A)=\dfrac{P(AB)}{P(A)}
$$

为在事件 $A$ 发生的条件下事件 $B$ 发生的条件概率。

乘法定理：设 $P(A)>0$，则有 $P(AB)=P(B|A)P(A)$。

乘法定理可以推广到多个事件的积事件的情况。

全概率公式：设试验 $E$ 的样本空间为 $S$，$A$ 为 $E$ 的事件，$B _ 1,B _ 2,\cdots ,B _ n$ 为 $S$ 的一个划分，且 $P(B _ i)>0\quad (i=1,2,\cdots ,n)$，则

$$
P(A) = P(A|B _ 1)P(B _ 1)+P(A|B _ 2)P(B _ 2) + \cdots + P(A|B _ n)P(B _ n)
$$

贝叶斯公式：设试验 $E$ 的样本空间为 $S$，$A$ 为 $E$ 的事件，$B _ 1,B _ 2,\cdots ,B _ n$ 为 $S$ 的一个划分，且 $P(A)>0,P(B _ i)>0\quad (i=1,2,\cdots ,n)$，则

$$
P(B _ i|A)=\dfrac{P(A|B _ i)P(B _ i)}{\displaystyle\sum _ {j=1}^{n}{P(A|B _ j)P(B _ j)}},i=1,2,\cdots,n
$$

其中 $P(B _ i)$ 称为先验概率，$P(B _ i|A)$ 称为后验概率，$P(A|B _ i)$ 称为似然概率。

### 独立性

独立：设 $A,B$ 是两事件，如果满足等式 $P(AB)=P(A)P(B)$，则称事件 $A,B$ 相互独立。简称 $A,B$ 独立。

设 $A,B$ 是两事件，且 $P(A)>0$。若 $A,B$ 相互独立，则 $P(B|A)=P(B)$。反之亦然。

若事件 $A$ 与 $B$ 相互独立，则下边各对事件也相互独立：

$$
A\text{与} \overline{B} \quad \overline{A}\text{与} {B} \quad \overline{A}\text{与} \overline{B}
$$

一般的，设 $A _ 1,A _ 2,\cdots,A _ n$ 是 $n$ 个事件，如果对于其中任意 2 个，任意 3 个，···，任意 $n$ 个事件的积事件的概率，都等于各事件概率之积，则称事件 $A _ 1,A _ 2,\cdots,A _ n$ 相互独立。

## 随机变量及其分布

### 随机变量

随机变量：设随机试验的样本空间为 $S=\lbrace e \rbrace$。$X=X(e)$ 是定义在样本空间 $S$ 上的实值单值函数。称 $X=X(e)$ 为随机变量。

### 离散型随机变量及其分布律

离散型随机变量：有些随机变量，它全部可能取到的值为有限个或可列的无限多个，这种随机变量称为离散型随机变量。

离散型随机变量的分布律

一：两点分布

设随机变量 $X$ 只可能取 0 与 1 两个值，它的分布律是

$$
P\lbrace X=k\rbrace =p^k(1-p)^{1-k},k=0,1 (0<p<1)
$$

则称 $X$ 服从以 $p$ 为参数的 $(0-1)$ 分布或两点分布。

二：二项分布

设试验 $E$ 只有两个可能结果：$A$ 和 $\overline{A}$，则称 $E$ 为伯努利试验。设 $P(A)=p(0<p<1)$，此时 $P(\overline{A})=1-p$。将 $E$ 独立重复地进行 $n$ 次，称这串试验为 $n$ 重伯努利试验。

以 $X$ 表示 $n$ 重伯努利试验中事件 $A$ 发生的次数，$X$ 是一个随机变量，分布律为

$$
P\lbrace X=k \rbrace =\binom{n}{k}p^k(1-p)^{n-k},k=0,1,2,\cdots,n
$$

称随机变量 $X$ 服从参数为 $n,p$ 的二项分布，记为 $X\sim b(n,p)$。

三：泊松分布

设随机变量 $X$ 所有可能取的值为 $0,1,2,\cdots$，而取各个值的概率为

其中 $\lambda >0$ 是常数。则称 $X$ 服从参数 $\lambda$ 的泊松分布，记为 $X\sim \pi(\lambda)$。

泊松定理：设 $\lambda >0$ 是一个常数，$n$ 是任意正整数，设 $np _ {n}=\lambda$，则对于任一固定的非负整数 $k$，有

$$
\lim _ {n\to \infty}{\binom {n}{k}p^{k} _ {n}(1-p _ n)^{n-k}=\dfrac{\lambda^ke^{-\lambda}}{k!}}
$$

### 随机变量的分布函数

分布函数：设 $X$ 是一个随机变量，$x$ 是任意实数，函数

$$
F(x)=P\lbrace x\leq x\rbrace ,-\infty<x<\infty
$$

称为 $X$ 的分布函数。

### 连续型随机变量及其概率密度

连续型随机变量：如果对于随机变量 $X$ 的分布函数 $F(x)$，存在非负可积函数 $f(x)$，使对于任意实数 $x$ 有

$$
F(x)=\int _ {-\infty}^{x}f(t)\mathrm{d}t
$$

则称 $X$ 为连续型随机变量，$f(x)$ 称为 $X$ 的概率密度函数，简称概率密度。

一：均匀分布

若连续型随机变量 $X$ 具有概率密度

$$
f(x)=\begin{cases}\dfrac{1}{b-a},a<x<b\\ 0,\text{其他}\end{cases}
$$

则称 $X$ 在区间 $(a,b)$ 上服从均匀分布，记为 $X\sim U(a,b)$。

二：指数分布

若连续型随机变量 $X$ 的概率密度为

$$
f(x)=\begin{cases}\dfrac{1}{\theta}e^{-\frac{x}{\theta}},x>0
\\ 0,\text{其他}\end{cases}
$$

其中 $\theta>0$ 为常数，则称 $X$ 服从参数为 $\theta$ 指数分布。

指数分布具有无记忆性。

三：正态分布

若连续型随机变量 $X$ 的概率密度为

$$
f(x)=\dfrac{1}{\sqrt{2\pi}\sigma}e^{-\dfrac{(x-\mu)^2}{2\sigma^2}},-\infty<x<+\infty
$$

其中 $\mu ,\sigma$ 为常数，则称 $X$ 服从参数为 $\mu ,\sigma$ 的正态分布或高斯分布，记为 $X\sim N(\mu,\sigma)$。

1. 曲线关于 $x=\mu$ 对称，这表明对于任意 $h>0$ 有
   $$
   P\lbrace \mu -h<X\leq \mu \rbrace =P\lbrace \mu<X\leq \mu +h \rbrace
   $$
2. 当 $x=\mu $ 时取到最大值
   $$
   f(\mu)=\dfrac{1}{\sqrt{2\pi}\sigma}
   $$

特别的，当 $\mu =0,\sigma =1$ 时，称随机变量 $X$ 服从标准正态分布。其概率密度和分布密度分别用 $\varphi ,\varPhi$ 表示，即有

$$
\varphi(x)=\dfrac{1}{\sqrt{2\pi}}\mathrm{e}^{-\frac{x^2}{2}}
$$

$$
\varPhi(x)=\dfrac{1}{\sqrt{2\pi}}\int _ {-\infty}^{x}\mathrm{e}^{-\frac{t^2}{2}}\mathrm{d}t
$$

易知 $\varPhi(-x)=1-\varPhi(x)$。

引理：若 $X\sim N(\mu,\sigma ^2)$，则 $Z=\dfrac{X-\mu}{\sigma}\sim N(0,1)$。

### 随机变量的函数的分布

定理：设随机变量 $X$ 具有概率密度 $f _ X(x),-\infty < x<\infty $，又设函数 $g(x)$ 处处可导且恒有 $g^{\prime}(x)>0$ （或恒有 $g^{\prime}(x)<0$ ），则 $Y=g(X)$ 是连续型随机变量，其概率密度为

$$
f _ Y(y)=\begin{cases}
f _ X[h(y)]|h^{\prime}(y)|,\alpha<y<\beta \\ 0,\text{其他}
\end{cases}
$$

其中 $\alpha =\min\lbrace g(-\infty),g(\infty) \rbrace $，$\beta =\max\lbrace g(-\infty),g(\infty) \rbrace $，$h(y)$ 是 $g(x)$ 的反函数。

## 多维随机变量及其分布

### 二维随机变量

二维随机变量：一般的，设 $E$ 是一个随机试验，它的样本空间是 $S=\lbrace e \rbrace $，设 $X=X(e)$ 和 $Y=Y(e)$ 是定义在 $S$ 上的随机变量，由它们构成的一个向量 $(X,Y)$，叫做二维随机向量或二维随机变量。

定义：设 $(X,Y)$ 是二维随机变量，对于任意实数 $x,y$，二元函数：

$$
F(x,y)=P\lbrace (X\leq x)\cap (Y \leq y) \rbrace =P\lbrace X\leq x,Y\leq y \rbrace
$$

称为二维随机变量 $(X,Y)$ 的分布函数，或称为随机变量 $X$ 和 $Y$ 的联合分布函数。

分布函数 $F(x,y)$ 具有以下基本性质：

1. $F(x,y)$ 是变量 $x$ 和 $y$ 的不减函数，即对于任意固定的 $y$，当 $x _ 2>x _ 1$ 时 $F(x _ 2,y)\geq F(x _ 1,y)$；对于任意固定的 $x$，当 $y _ 2>y _ 1$ 时 $F(x,y _ 2)\geq F(x,y _ 1)$。
2. $0\leq F(x,y)\leq 1$，且对于任意固定的 $y$，$F(-\infty ,y)=0$。对于任意固定的 $x$，$F(x,-\infty)=0$。$F(-\infty,-\infty)=0$，$F(\infty ,\infty)=1$。
3. $F(x+0,y)=F(x,y)$，$F(x,y+0)=F(x,y)$，即 $F(x,y)$ 关于 $x$ 右连续，关于 $y$ 也右连续。
4. 对于任意 $(x _ 1,y _ 1)$，$(x _ 2,y _ 2)$，$x _ 1<x _ 2$，$y _ 1<y _ 2$，下述不等式成立：

$$
F(x _ 2,y _ 2)-F(x _ 2,y _ 1)+F(x _ 1,y _ 1)-F(x _ 1,y _ 2)\geq 0
$$

如果二维随机变量 $(X,Y)$ 全部可能取到的值是有限对或可列无限多对，则称 $(X,Y)$ 是离散型的随机变量。

分布律：设二维随机变量 $(X,Y)$ 所有可能取的值为 $(x _ i,y _ j),i,j=1,2.\cdots$，记 $P\lbrace X=x _ i,Y=y _ i \rbrace =p _ {ij},i,j=1,2,\cdots$，则由概率的定义有

$$
p _ {ij}\geq 0,\sum _ {i=1}^{\infty}\sum _ {j=1}^{\infty}p _ {ij}=1
$$

我们称 $P\lbrace X=x _ i,Y=y _ i \rbrace =p _ {ij},i,j=1,2,\cdots$ 为二维离散型随机变量 $(X,Y)$ 的分布律，或称为随机变量 $X$ 和 $Y$ 的联合分布律。

将 $(X,Y)$ 看成一个随机点的坐标，离散型随机变量 $X$ 和 $Y$ 的联合分布函数为

$$
F(x,y)=\sum _ {x _ i\leq x}\sum _ {y _ i\leq y}p _ {ij}
$$

其中和式是对一切满足 $x _ i\leq x,y _ i\leq y$ 的 $i,j$ 来求和的。

对于二维随机变量 $(X,Y)$ 的分布函数 $F(x,y)$，如果存在非负的可积函数 $f(x,y)$ 使对于任意 $x,y$ 有

$$
F(x,y)=\int _ {-\infty}^{y}\int _ {-\infty}^{x}f(u,v)\mathrm{d}u\mathrm{d}v
$$

则称 $(X,Y)$ 是连续型的二维随机变量，函数 $f(x,y)$ 称为二维随机变量 $(X,Y)$ 的概率密度，或称为随机变量 $X$ 和 $Y$ 的联合概率密度。

概率密度 $f(x,y)$ 有以下性质：
1. $f(x,y)\geq 0$。
2. $\int _ {-\infty}^{\infty}\int _ {-\infty}^{\infty}f(x,y)\mathrm{d}x\mathrm{d}y=F(\infty,\infty)=1$。
3. 设 $G$ 是 $xOy$ 平面上的区域，点 $(X,Y)$ 落在 $G$ 内的概率为：
   $$
   P\lbrace (X,Y)\in G \rbrace =\iint _ {G}f(x,y)\mathrm{d}x\mathrm{d}y
   $$
4. 若 $f(x,y)$ 在点 $(x,y)$ 连续，则有：
   $$
   \frac{\partial^2 F(x,y)}{\partial x\partial y}=f(x,y)
   $$

一般，设 $E$ 是一个随机试验，它的样本空间是 $S=\lbrace e \rbrace $，设 $X _ 1=X _ 1(e),\cdots,X _ n=X _ n(e)$ 是定义在 $S$ 上的随机变量，由它们构成的一个 $n$ 维向量 $(X _ 1,\cdots,X _ n)$ 叫做 $n$ 维随机变量。

对于任意 $n$ 个实数 $x _ 1,\cdots,x _ n$，$n$ 元函数

$$
F(x _ 1,\cdots,x _ n)=P\lbrace X _ 1\leq x _ 1,\cdots,X _ n\leq x _ n \rbrace
$$

称为 $n$ 维随机变量 $(X _ 1,\cdots,X _ n)$ 的分布函数或随机变量 $X _ 1,\cdots,X _ n$ 的联合分布函数。

### 边缘分布

边缘分布律：对于离散型随机变量 $(X,Y)$，记

$$
p _ {i \cdot} =P\lbrace X=x _ i\rbrace =\sum _ {j=1}^{\infty}p _ {ij} ,i = 1,2,\cdots
$$

$$
p _ {\cdot j} =P\lbrace X=x _ j\rbrace =\sum _ {i=1}^{\infty}p _ {ij} ,i = 1,2,\cdots
$$

分别称 $p _ {i \cdot}$ 和 $p _ {\cdot j}$ 为 $(X,Y)$ 关于 $X$ 和关于 $Y$ 的边缘分布律。

边缘概率密度：对于连续型随机变量 $(X,Y)$，设它的概率密度为 $f(x,y)$，由于

$$
F _ X(x)=F(x,\infty)=\int _ {-\infty}^{x}[\int _ {-\infty}^{\infty}f(x,y)\mathrm{d}y]\mathrm{d}y
$$

 $X$ 是一个连续型随机变量，且其概率密度为

$$
f _ X(x)=\int _ {-\infty}^{\infty}f(x,y)\mathrm{d}y
$$

 $Y$ 是一个连续型随机变量，且其概率密度为

$$
f _ Y(y)=\int _ {-\infty}^{\infty}f(x,y)\mathrm{d}x
$$

 $f _ X(x)$ 分别为 $f _ Y(y)$ 为 $(X,Y)$ 关于 $X$ 和关于 $Y$ 的边缘概率密度。

二维正态分布：设二维随机变量 $(X,Y)$ 的概率密度为

$$
f(x,y)=\dfrac{1}{2\pi \sigma _ 1 \sigma _ 2 \sqrt{1-\rho^2}} \exp\lbrace \dfrac{-1}{2(1-\rho^2)}[\dfrac{(x-\mu _ 1)^2}{\sigma _ 1 ^2}-2\rho \dfrac{(x-\mu _ 1)(y-\mu _ 2)}{\sigma _ 1 \sigma _ 2}+\dfrac{(y-\mu _ 2)^2}{\sigma _ 2 ^2}] \rbrace
$$

其中 $\mu _ 1,\mu _ 2,\sigma _ 1,\sigma _ 2,\rho$ 都是常数，且 $\sigma _ 1 >0,\sigma _ 2>0,-1<\rho<1$，我们称 $(X,Y)$ 为服从参数为 $\mu _ 1,\mu _ 2,\sigma _ 1,\sigma _ 2,\rho$ 的二维正态分布，记为 $(X,Y)\sim N(\mu _ 1,\mu _ 2,\sigma _ 1,\sigma _ 2,\rho)$。

二维正态分布的两个边缘分布都是一维正态分布，并且都不依赖与参数 $\rho$，亦即对于给定的 $\mu _ 1,\mu _ 2,\sigma _ 1,\sigma _ 2$，不同的 $\rho$ 对于不同的二维正态分布，他们的边缘分布是一样的。

### 条件分布

条件分布律：设 $(X,Y)$ 是二维离散型随机变量，对于固定的 $j$，若 $P\lbrace Y=y _ j \rbrace >0$ 则称

$$
P\lbrace X=x _ i|Y=y _ j \rbrace =\dfrac{P\lbrace X=x _ i,Y=y _ j \rbrace }{P\lbrace Y=y _ j \rbrace }=\dfrac{p _ {ij}}{p _ {\cdot j}}
$$

为在 $Y=y _ i$ 条件下随机变量 $X$ 的条件分布律。

同样的，对于固定的 $i$，若 $P\lbrace X=x _ i \rbrace $，则称

$$
P\lbrace Y=y _ j|X=x _ i \rbrace =\dfrac{P\lbrace X=x _ i,Y=y _ j \rbrace }{P\lbrace X=x _ i \rbrace }=\dfrac{p _ {ij}}{p _ {i \cdot}}
$$

为在 $X=x _ i$ 条件下随机变量 $Y$ 的条件分布律。

条件概率密度：设二维随机变量 $(X,Y)$ 的概率密度为 $f(x,y)$，$(X,Y)$ 关于 $Y$ 的边缘概率密度为 $f _ Y(y)$。若对于固定的 $y,f _ Y(y)>0$，则称 $\dfrac{f(x,y)}{f _ Y(y)}$ 为在 $Y=y$ 的条件下 $X$ 的条件概率密度，记为

$$
f _ {X|Y}(x|y)=\dfrac{f(x,y)}{f _ Y(y)}
$$

称 $\int _ {-\infty}^{x}f _ {X|Y}(x|y)\mathrm{d}x=\int _ {-\infty}^{x}\dfrac{f(x,y)}{f _ Y(y)}\mathrm{d}x$ 为在 $Y=y$ 的条件下 $X$ 的条件分布函数，记为 $P\lbrace X\leq x| Y=y \rbrace $ 或 $F _ {X|Y}(x|y)$，即

$$
F _ {X|Y}(x|y)=P\lbrace X\leq x|Y=y \rbrace = \int _ {-\infty}^{x}\dfrac{f(x,y)}{f _ Y(y)}\mathrm{d}x
$$

类似的，可以定义 $f _ {Y|X}(y|x)=\dfrac{f(x,y)}{f _ Y(x)}$ 和 $F _ {Y|X}(y|x)=\int _ {-\infty}^{y}\dfrac{f(x,y)}{f _ X(x)}$。

### 相互独立的随机变量

独立：设 $F(x,y)$ 及 $F _ X(x)$，$F _ Y(y)$ 分别是二维随机变量 $(X,Y)$ 的分布函数及边缘分布函数，若对于所有的 $x,y$ 有

$$
P\lbrace X\leq x,Y\leq y \rbrace =P\lbrace X\leq x \rbrace P\lbrace Y\leq y \rbrace
$$

即，$F(x,y)=F _ X(x)F _ Y(y)$。
则称随机变量 $X$ 和 $Y$ 是相互独立的。

设 $(X,Y)$ 是连续型随机变量，$f(x,y)$，$f _ X(x)$，$F _ Y(y)$ 分别为 $(X,Y)$ 的概率密度和边缘概率密度，则 $X$ 和 $Y$ 相互独立的条件等价于：等式

$$
f(x,y)=f _ X(x)f _ Y(y)
$$

在平面上几乎处处成立（指平面上除去“面积”为零的集合）。

当 $(X,Y)$ 是离散型随机变量时，$X$ 和 $Y$ 相互独立的条件等价于：对于 $(X,Y)$ 的所有可能取的值 $(x _ i,y _ j)$ 有，

$$
P\lbrace X=x _ i,Y=y _ j\rbrace =P\lbrace X=x _ i \rbrace P\lbrace Y=y _ j \rbrace
$$

对于二维正态随机变量 $(X,Y)$，$X$ 和 $Y$ 相互独立的充要条件是参数 $\rho = 0$。

二维随机变量相互独立可以推广到多维形式，这里不做赘述。

定理：设 $(X _ 1,X _ 2,\cdots,X _ m)$ 和 $(Y _ 1,Y _ 2,\cdots,Y _ n)$ 相互独立，则 $X _ i,(i=1,2,\cdots,m)$ 和 $Y _ i,(j=1,2,\cdots,n)$ 相互独立。又若 $h,g$ 是连续函数，则 $h(X _ 1,X _ 2,\cdots,X _ m)$ 和 $g(Y _ 1,Y _ 2,\cdots,Y _ n)$ 相互独立。

### 两个随机变量的函数分布

一：$Z=X+Y$ 的分布

设 $(X,Y)$ 是二维连续型随机变量，它具有概率密度 $f(x,y)$。则 $Z=X+Y$ 仍为连续型随机变量，其概率密度为

$$
f _ {X+Y}(z)=\int _ {-\infty}^{\infty}f(z-y,y)\mathrm{d}y
$$

或

$$
f _ {X+Y}(z)=\int _ {-\infty}^{\infty}f(x,z-x)\mathrm{d}x
$$

又若 $X$ 和 $Y$ 相互独立，设 $(X,Y)$ 关于 $X,Y$ 的边缘密度分别为 $f _ X(x),f _ Y(y)$，则

$$
f _ {X+Y}(z)=\int _ {-\infty}^{\infty}f _ X(z-y)f _ Y(y)\mathrm{d}y
$$

和

$$
f _ {X+Y}(z)=\int _ {-\infty}^{\infty}f _ X(x)f _ Y(z-x)\mathrm{d}x
$$

这两个公式称为 $f _ X$ 和 $f _ Y$ 的卷积公式，记为 $f _ X\ast f _ Y$。即

$$
f _ X\ast f _ Y=\int _ {-\infty}^{\infty}f _ X(z-y)f _ Y(y)\mathrm{d}y=\int _ {-\infty}^{\infty}f _ X(x)f _ Y(z-x)\mathrm{d}x
$$

若 $X _ i\sim N(\mu _ i,\sigma _ i^2),(i=1,\cdots,n)$，且它们相互独立，则它们的和 $Z=X _ 1+\cdots+X _ n$ 仍然服从正态分布，且有 $Z\sim N(\mu _ 1+\cdots+\mu _ n,\sigma _ 1^2+\cdots+\sigma _ n^2)$。

更一般的，可以证明有限个相互独立的正态随机变量的线性组合仍然服从正态分布。

二：$Z=\dfrac{Y}{X}$ 的分布，$Z=XY$ 的分布

设 $(X,Y)$ 是二维连续型随机变量，它具有概率密度 $f(x,y)$，则 $Z=\dfrac{Y}{X}$，$Z=XY$ 仍然为连续型随机变量，其概率密度为

$$
f _ {\frac{Y}{X}}(z)=\int _ {-\infty}^{\infty} |x| f(x,xz)\mathrm{d}x
$$

$$
f _ {XY}(z)=\int _ {-\infty}^{\infty} \frac{1}{|x|} f(x,\frac{z}{x})\mathrm{d}x
$$

又若 $X$ 和 $Y$ 相互独立，设 $(X,Y)$ 关于 $X,Y$ 的边缘密度分别为 $f _ X(x),f _ Y(y)$，则

$$
f _ {\frac{Y}{X}}(z)=\int _ {-\infty}^{\infty} |x| f _ X(x)f _ Y(xz)\mathrm{d}x
$$

$$
f _ {XY}(z)=\int _ {-\infty}^{\infty} \frac{1}{|x|} f _ X(x)f _ Y(\frac{z}{x})\mathrm{d}x
$$

三：$M=\max \lbrace X,Y \rbrace $ 及 $N = \min \lbrace X,Y \rbrace $ 的分布

设 $(X,Y)$ 是两个相互独立的随机变量，它们的分布函数分别为 $F _ X(x)$ 和 $F _ Y(y)$。现在来求 $M=\max \lbrace X,Y \rbrace $ 及 $N = \min \lbrace X,Y \rbrace $ 的分布函数。
由于 $M=\max \lbrace X,Y \rbrace $ 不大于 $z$ 等价于 $X$ 和 $Y$ 都不大于 $z$，故有

$$
P\lbrace M\leq z \rbrace =P\lbrace X\leq z,Y\leq z \rbrace
$$

又由于 $X$ 和 $Y$ 相互独立，得到 $M=\max \lbrace X,Y \rbrace $ 的分布函数为

$$
F _ {\max}(z)=P\lbrace M\leq z \rbrace =P\lbrace X\leq z,Y\leq z \rbrace =P\lbrace X\leq z \rbrace P\lbrace Y\leq z \rbrace
$$

即有 $F _ {\max}(z)=F _ X(z)F _ Y(z)$。

类似的，可得 $N = \min \lbrace X,Y \rbrace $ 的分布函数为

$$
F _ {\min}(z)=P\lbrace N\leq z \rbrace = 1-P\lbrace N>z \rbrace =1-P\lbrace X>z,Y>z \rbrace =1-P\lbrace X>z \rbrace P\lbrace Y>z \rbrace
$$

即 $F _ {\min}(z)=1-[1-F _ X(z)](1-F _ Y(z))$。

设 $X _ 1\cdots,X _ n$ 是 $n$ 个相互独立的随机变量，它们的分布函数分别为 $F _ {X _ i}(x _ i),(i=1,\cdots,n)$，则 $M=\max \lbrace X,Y \rbrace $ 及 $N = \min \lbrace X,Y \rbrace $ 的分布函数分别为

$$
F _ {\max}(z)=F _ {X _ 1}(z)\cdots F _ {X _ n}(z)
$$

$$
F _ {\min}(z)=1-[1-F _ {X _ 1}(z)]\cdots [1-F _ {X _ n}(z)]
$$

特别的，当 $X _ 1\cdots,X _ n$ 相互独立且具有相同的分布函数 $F(x)$ 时有

$$
F _ {\max}(z)=[F(z)]^n
$$

$$
F _ {\min}(z)=1-[1-F(z)]^n
$$

## 随机变量的数字特征

### 数学期望

数学期望：设离散型随机变量 $X$ 的分布律为 $P\lbrace X=x _ k \rbrace =p _ k,k=1,2,\cdots$。若级数 $\sum _ {k=1}^{\infty}x _ kp _ k$ 绝对收敛，则称级数 $\sum _ {k=1}^{\infty}x _ kp _ k$ 的和为随机变量 $X$ 的数学期望，记为 $E(X)$，即 $E(X)=\sum _ {k=1}^{\infty}x _ kp _ k$。
设连续型随机变量 $X$ 的概率密度为 $f(x)$，若积分 $\int _ {-\infty}^{\infty}xf(x)\mathrm{d}x$ 绝对收敛，则称积分 $\int _ {-\infty}^{\infty}xf(x)\mathrm{d}x$ 的值为随机变量 $X$ 的数学期望，记为 $E(X)$，即 $E(X)=\int _ {-\infty}^{\infty}xf(x)\mathrm{d}x$。

数学期望简称期望，又称为均值。

定理：设 $Y$ 是随机变量 $X$ 的函数：$Y=g(X)$ （ $g$ 是连续函数）。

1. 如果 $X$ 是离散型随机变量，它的分布律为 $P\lbrace X=x _ k \rbrace =p _ k,k=1,2,\cdots$。若 $\sum _ {k=1}^{\infty}g(x _ k)p _ k$ 绝对收敛，则有

$$
E(Y)=E[g(X)]=\sum _ {k=1}^{\infty}g(x _ k)p _ k
$$

2. 如果 $X$ 是连续型随机变量，它的概率密度为 $f(x)$，若 $\int _ {-\infty}^{\infty}f(x)\mathrm{d}x$ 绝对收敛，则有

$$
E(Y)=E[g(X)]=\int _ {-\infty}^{\infty}g(x)f(x)\mathrm{d}x
$$

定理：设 $Z$ 是随机变量 $X,Y$ 的函数 $Z=g(X,Y)$ （ $g$ 是连续函数），那么，$Z$ 是一个一维随机变量。若二维随机变量 $(X,Y)$ 的概率密度为 $f(x,y)$，则有

$$
E(Z)=E[g(X,Y)]=\int _ {-\infty}^{\infty}\int _ {-\infty}^{\infty}g(x,y)f(x,y)\mathrm{d}x\mathrm{d}y
$$

这里设上式右边的积分绝对收敛，又若 $(X,Y)$ 为离散型随机变量，其分布律为 $P\lbrace X=x _ i,Y=y _ i \rbrace =p _ {ij},i,j=1,2,\cdots$，则有

$$
E(Z)=E[g(X,Y)]=\sum _ {j=1}^{\infty}\sum _ {i=1}^{\infty}g(x _ i,y _ i)p _ {ij}
$$

这里设上式右边的级数绝对收敛。

数学期望的几个重要性质：

1. 设 $C$ 是常数，则有 $E(C)=C$。
2. 设 $X$ 是一个随机变量，$C$ 是常数，则有 $E(CX)=cE(X)$。
3. 设 $X,Y$ 是两个随机变量，则有 $E(X+Y)=E(X)+E(Y)$。
4. 设 $X,Y$ 是相互独立的随机变量，则有 $E(XY)=E(x)E(Y)$。

### 方差

方差：设 $X$ 是一个随机变量，若 $E\lbrace [X-E(X)]^2 \rbrace $ 存在，则称 $E\lbrace [X-E(X)]^2 \rbrace $ 为 $X$ 的方差，记为 $D(X)$ 或 $\mathrm{Var}(X)$，即

$$
D(X)=\mathrm{Var}(X)=E\lbrace [X-E(X)]^2\rbrace
$$

在应用上还引入量 $\sqrt{D(X)}$，记为 $\sigma(X)$，称为标准差或均方差。

对于离散型随机变量，有

$$
D(X)=\sum _ {k=1}^{\infty}[x _ k-E(X)]^2p _ k
$$

其中 $P\lbrace X=x _ k \rbrace =p _ k,k=1,2,\cdots $ 是 $X$ 的分布律。

对于连续型随机变量，有

$$
D(X)=\int _ {-\infty}^{\infty}[x-E(X)]^2f(x)\mathrm{d}x
$$

其中 $f(x)$ 是 $X$ 的概率密度。

随机变量的方差可按下列公式计算

$$
D(X)=E(X^2)-[E(X)]^2
$$

设随机变量 $X$ 具有数学期望 $E(X)=\mu$，方差 $D(X)=\sigma^2\neq 0$。记

$$
X^\ast=\dfrac{X-\mu}{\sigma}
$$

则

$$
E(X^\ast)=\dfrac{1}{\sigma}E(X-\mu)=\dfrac{1}{\sigma}[E(X)-\mu]=0
$$

$$
D(X^\ast)=E(X^\ast)-[E(X^\ast)]^2=E[(\dfrac{X-\mu}{\sigma})^2]=\dfrac{1}{\sigma^2}E[(X-\mu)^2]=1
$$

即 $X^\ast$ 的数学期望为 $0$，方差为 $1$。 $X^\ast$ 称为 $X$ 的标准化变量。

方差的几个重要性质：

1. 设 $C$ 是常数，则 $D(C)$。
2. 设 $X$ 是随机变量，$C$ 是常数，则有
 $D(CX)=C^2D(X),D(X+c)=D(X)$
3. 设 $X,Y$ 是两个随机变量，则有

$$
D(X+Y)=D(X)+D(Y)+2E\lbrace (X-E(X))(Y-E(Y)) \rbrace
$$

特别的，若 $X,Y$ 相互独立，则有

$$
D(X+Y)=D(X)+D(Y)
$$

这一性质可以推广到任意有限多个相互独立的随机变量之和的情况。

4. $D(X)=0$ 的充要条件设 $X$ 以概率 1 取常数 $E(X)$，即

$$
P\lbrace X=E(X) \rbrace =1
$$

切比雪夫不等式：设随机变量 $X$ 具有数学期望 $E(X)=\mu$，方差 $D(X)=\sigma^2$，则对于任意正数 $\varepsilon$，不等式 $P\lbrace |X-\mu|\geq \varepsilon \rbrace \leq \frac{\sigma^2}{\varepsilon^2}$ 成立。

常见的概率分布：

|  分布  |  参数 |  分布律或概率密度 |  数学期望 | 方差  |
|-----|-----|-----|-----|-----|
| $(0-1)$ 分布  |  $0<p<1$   |  $P\lbrace X=k\rbrace =p^k(1-p)^k,k=0,1$   |  $p$  |  $p(1-p)$  |
|  二项分布  |  $n\geq 1,0<p<1$   |  $P\lbrace X=k \rbrace = {n\choose k}p^k(1-p)^{n-k},k=0,1,\cdots,$   |  $np$  |  $np(1-p)$  |
|  帕斯卡分布  |  $r\geq 1,0<p<1$   | $P\lbrace X=k \rbrace ={k-1\choose r-1}p^r(1-p)^{k-r},k=r,r+1,\cdots$   |   $\frac{1}{p}$ |  $\frac{1-p}{p^2}$  |
|  泊松分布  |  $\lambda>0$   |  $P\lbrace X=k \rbrace =\frac{\lambda^k\mathrm{e}^{-\lambda}}{k!},k=0,1,2,\cdots$   |  $\lambda$  |  $\lambda$  |
|  均匀分布  |  $a<b$   |  $f(x)=\begin{cases} \frac{1}{b-a},a<x<b \\ 0,\text{其他}\end{cases}$   |  $\frac{a+b}{2}$  |  $\frac{(b-a)^2}{12}$  |
|  正态分布  |  $\mu , \sigma(\sigma>0)$   |   $f(x)=\frac{1}{\sqrt{2\pi}\sigma}\mathrm{e}^{-(x-\mu)^2/(2\sigma^2)}$  |  $\mu$  |  $\sigma^2$  |
|  $\Gamma$ 分布  |   $\alpha,\beta>0$  |  $f(x)=\begin{cases} \frac{1}{\beta^{\alpha}\Gamma(\alpha)}x^{\alpha-1}\mathrm{e}^{-x/\beta},x>0 \\ 0,\text{其他} \end{cases}$   |  $\alpha \beta$  |  $\alpha \beta^2$  |
|  超几何分布  |  $N,M,n,(M\leq N),(n\leq N)$   |  $\frac{C _ M^kC _ {N-M}^{n-k}}{C _ N^k},k\in \mathbb{Z},\mathrm{max} \lbrace 0,n-N+M \rbrace \leq k\leq \mathrm{min} \lbrace n,M \rbrace $   |  $\frac{nM}{N}$  |  $\frac{nM}{N}(1-\frac{M}{N})(\frac{N-n}{N-1})$  |
|  几何分布  |  $0<p<1$   |  $P\lbrace X=k \rbrace =(1-p)^{k-1}p,k=1,2,\cdots$   | $\frac{1}{p}$   |  $\frac{1-p}{p^2}$  |
|  指数分布  |   $\theta>0$  |   $f(x)=\begin{cases} \frac{1}{\theta}\mathrm{e}^{-x/\theta},x>0 \\ 0,\text{其他} \end{cases}$  |  $\theta$  |  $\theta^2$  |
|  $\chi^2$ 分布  |  $n\geq 1$   |  $f(x)=\begin{cases} \frac{1}{2^{n/2}\Gamma(n/2)}x^{n/2-1}\mathrm{e}^{-x/2},x>0 \\ 0,\text{其他}\end{cases}$   |   $n$ |  $2n$  |
|  韦布尔分布  |  $\eta>0,\beta>0$   |   $f(x)=\begin{cases} \frac{\beta}{\eta}(\frac{x}{\eta})^{\beta -1}\mathrm{e}^{-(\frac{x}{\eta})^\beta},x>0\\ 0,\text{其他} \end{cases}$  |  $\eta \Gamma(\frac{1}{\beta}+1)$  |  $\eta^2\lbrace \Gamma(\frac{2}{\beta}+1)-[\Gamma(\frac{1}{\beta}+1)]^2 \rbrace $  |
|  瑞利分布  |  $\sigma>0$   |  $f(x)=\begin{cases} \frac{x}{\sigma^2}\mathrm{e}^{-x^2/(2\sigma^2)},x>0 \\ 0,\text{其他} \end{cases}$   |  $\sqrt{\frac{\pi}{2}}\sigma$  |  $\frac{4-\pi}{2}\sigma^2$  |
|  $\beta$ 分布  |  $\alpha>0,\beta>0$   |   $f(x)=\begin{cases} \frac{\Gamma(\alpha+\beta)}{\Gamma(\alpha)\Gamma(\beta)}x^{\alpha-1}(1-x)^{\beta-1},0<x<1 \\ 0,\text{其他} \end{cases}$  |  $\frac{\alpha}{\alpha+\beta}$  |  $\frac{\alpha\beta}{(\alpha+\beta)^2(\alpha+\beta+1)}$  |
|  对数正态分布  |   $\mu,\sigma(\sigma>0)$  |  $f(x)=\begin{cases} \frac{1}{\sqrt{2\pi}\sigma x}\mathrm{e}^{-(\ln x-\mu)^2/(2\sigma^2)},x>0 \\ 0,\text{其他} \end{cases}$   |   $\mathrm{e}^{\mu+\frac{\sigma^2}{2}}$ |  $\mathrm{e}^{2\mu^2+\sigma^2}(\mathrm{e}^{\sigma^2}-1)$  |
|  柯西分布  |  $a,\lambda(\lambda>0)$   |  $f(x)=\frac{1}{\pi}\frac{\lambda}{\lambda^2+(x-a)^2}$   |  不存在  |  不存在  |
|  $t$ 分布  |  $n\geq 1$   |  $f(x)=\frac{\Gamma(\frac{n+1}{2})}{\sqrt{n\pi}\Gamma(n/2)}(1+\frac{x^2}{n})^{-(n+1)/2}$   |  $0,n>1$  |  $\frac{n}{n-2},n>2$  |
|  $F$ 分布  |   $n _ 1,n _ 2$  |  $f(x)=\begin{cases} \frac{\Gamma[(n _ 1+n _ 2)/2]}{\Gamma(n _ 1/2)\Gamma(n _ 2/2)}(\frac{n _ 1}{n _ 2})(\frac{n _ 1}{n _ 2}x)^{n _ 1/2-1}\times (1+\frac{n _ 1}{n _ 2}x)^{-(n _ 1+n _ 2)/2},x>0 \\ 0.\text{其他} \end{cases}$   |  $\frac{n _ 2}{n _ 2-2},n>2$  |  $\frac{2n _ 2^2(n _ 1+n _ 2-2)}{n _ 1(n _ 2-2)^2(n _ 2-4)},n _ 2>4$  |

### 协方差及相关系数

协方差与相关系数：量 $E\lbrace [X-E(X)] (Y-E(Y)) \rbrace$ 称为随机变量 $X$ 与 $Y$ 的协方差。记为 $\operatorname{Cov} (X,Y)$，即

$$
\operatorname{Cov}(X,Y)=E\lbrace [X-E(X)] (Y-E(Y)) \rbrace
$$

而

$$
\rho _ {XY}=\frac{\operatorname{Cov}(X,Y)}{\sqrt{D(X)}\sqrt{D(Y)}}
$$

称为随机变量 $X$ 与 $Y$ 的相关系数。

由定义，可以知道：

$$
\operatorname{Cov}(X,Y)=\operatorname{Cov}(Y,X),\operatorname{Cov}(X,X)=D(X)
$$

对于任意两个随机变量 $X$ 和 $Y$，下列等式成立：

$$
D(X+Y)=D(X)+D(Y)+2\operatorname{Cov}(X,Y)
$$

将 $\operatorname{Cov}(X,Y)$ 的定义式展开，易得

$$
\operatorname{Cov}(X,Y)=E(XY)-E(X)E(Y)
$$

这一式子常常用于计算协方差。

协方差的性质：

1. $\operatorname{Cov}(aX,bY)=ab\operatorname{Cov}(X,Y)$，$a,b$ 是常数。
2.

$$
\operatorname{Cov}(X _ 1+X _ 2,Y)=\operatorname{Cov}(X _ 1,Y)+\operatorname{Cov}(X _ 2,Y)
$$

考虑以 $X$ 的线性函数 $a+bX$ 来近似表示 $Y$，我们以均方误差

$$
e=E[(Y-(a+bX))^2]=E(Y^2)+b^2E(X^2)+a^2-2bE(XY)+2abE(X)-2aE(Y)
$$

来衡量以 $a+bX$ 近似表达 $Y$ 的好坏程度。$e$ 的值越小表示 $a+bX$ 与 $Y$ 的近似程度越好。这样，我们就取 $a,b$ 使 $e$ 取到最小，将 $e$ 分别关于 $a,b$ 求偏导数，并令它们等于零，得

$$
\begin{cases} \dfrac{\partial e}{\partial a}=2a+2bE(X)-2E(Y)=0 \\  \dfrac{\partial e}{\partial b}=2bE(X^2)-2E(XY)+2aE(X)=0  \end{cases}
$$

解得

$$
b _ 0=\dfrac{\operatorname{Cov}(X,Y)}{D(X)},a _ 0=E(Y)-b _ 0E(X)=E(Y)-E(X)\dfrac{\operatorname{Cov}(X,Y)}{D(X)}
$$

将 $A _ 0,b _ 0$ 代入 $e$ 的定义式中，有

$$
\min E\lbrace [Y-(a+bX)]^2 \rbrace =(1-\rho _ {XY}^2)D(Y)
$$

定理：$|\rho _ {XY}|\leq 1$。

定理：$|\rho _ {XY}|=1$ 的充要条件是，存在常数 $a,b$ 使 $P\lbrace Y=a+bX \rbrace =1$。

当 $|\rho _ {XY}|$ 较大时，称 $X,Y$ 线性相关的程度较好，当 $|\rho _ {XY}|$ 较小时，$X,Y$ 线性相关的程度较差。当 $|\rho _ {XY}|=1$ 时，称 $X$ 与 $Y$ 不相关。

当 $X,Y$ 服从二维正态分布时，$X$ 和 $Y$ 不相关与 $X$ 和 $Y$ 相互独立是等价的。

### 矩，协方差矩阵

原点矩：设 $X$ 和 $Y$ 是随机变量，若

$$
E(X^k),k=1,2,\cdots
$$

存在，称它为 $X$ 的 $k$ 阶原点矩，简称 $k$ 阶矩。

中心矩：若

$$
E\lbrace [X-E(X)]^k \rbrace ,k=1,2,3,\cdots
$$

存在，称它为 $X$ 的 $k$ 阶中心矩。

混合矩：若

$$
E(X^kY^l),k,l=1,2,\cdots
$$

存在，称它为 $X$ 和 $Y$ 的 $k+l$ 阶混合矩。

混合中心矩：若

$$
E\lbrace [X-E(X)]^k[Y-E(Y)]^l \rbrace ,k,l=1,2,\cdots
$$

存在，称它为 $X$ 和 $Y$ 的 $k+l$ 阶混合中心矩。

协方差矩阵：设 $n$ 维随机变量 $(X _ 1,\cdots,X _ n)$ 的二阶混合中心矩

$$
c _ {ij}=\operatorname{Cov}(X _ i,X _ j)=E\lbrace [X _ i-E(X _ i)](X _ j-E(X _ j)) \rbrace
$$

都存在，则称矩阵

$$
C=\begin{pmatrix}c _ {11}&c _ {12}&\cdots &c _ {1n} \\ c _ {21}&c _ {22}&\cdots &c _ {2n} \\ \vdots &\vdots &\ddots &\vdots \\ c _ {n1}&c _ {n2}&\cdots &c _ {nn}\end{pmatrix}
$$

为 $n$ 维随机变量 $(X _ 1,\cdots,X _ n)$ 的协方差矩阵。

## 大数定律及中心极限定理

### 大数定律

弱大数定理（辛钦大数定理）：设 $X _ 1,X _ 2,\cdots$ 是相互独立的，服从同一分布的随机变量序列，且具有数学期望 $E(X _ k)=\mu (k=1,2,\cdots)$。作前 $n$ 个变量的算术平均 $\frac{1}{n}\sum _ {k=1}^nX _ k$，则对于任意 $\varepsilon>0 $，有

$$
\lim _ {n\to \infty}P\lbrace |\frac{1}{n}\sum _ {k=1}^nX _ k-\mu| <\varepsilon \rbrace =1
$$

设 $Y _ 1,Y _ 2,\cdots$ 是一个随机变量序列，$a$ 是一个常数。若对于任意正数 $\varepsilon$，有

$$
\lim _ {n\to \infty}P\lbrace |Y _ n-a|< \varepsilon \rbrace =1
$$

则称序列 $Y _ 1,Y _ 2,\cdots$ 依概率收敛于 $a$，记为

$$
Y _ n\stackrel{P}{\longrightarrow} a
$$

依概率收敛的序列具有以下性质：

设 $X _ n\stackrel{P}{\longrightarrow} a$，$Y _ n\stackrel{P}{\longrightarrow} b$，又设函数 $g(x,y)$ 在点 $(a,b)$ 连续，则

$$
g(X _ n,Y _ n)\stackrel{P}{\longrightarrow} g(a,b)
$$

弱大数定理（辛钦大数定理）：设随机变量 $X _ 1,X _ 2,\cdots$，相互独立，服从同一分布且具有数学期望 $E(X _ k)=\mu (k=1,2,\cdots)$，则序列 $\overline{X}=\frac{1}{n}\sum _ {k=1}^nX _ k$ 依概率收敛于 $\mu $，即 $\overline{X} \stackrel{P}{\longrightarrow} \mu $。

伯努利大数定理：设 $f _ A$ 是 $n$ 次独立重复试验中事件 $A$ 发生的次数，$p$ 是事件 $A$ 在每次试验中发生的概率，则对于任意正数 $\varepsilon >0$，有

$$
\lim _ {n\to \infty}P\lbrace |\frac{f _ A}{n}-p|<\varepsilon \rbrace =1
$$

或

$$
\lim _ {n\to \infty}P\lbrace |\frac{f _ A}{n}-p|\geq \varepsilon \rbrace =0
$$

### 中心极限定理

独立同分布的中心极限定理：设随机变量 $X _ 1,X _ 2,\cdots$ 相互独立，且服从同一分布，且具有数学期望和方差：$E(X _ k)=\mu $，$D(X _ k)=\sigma^2>0$，$(k=1,2,\cdots)$，则随机变量之和 $\sum _ {k=1}^nX _ k$ 的标准化变量

$$
Y _ n=\dfrac{\sum _ {k=1}^nX _ k-E(\sum _ {k=1}^nX _ k)}{\sqrt{D(\sum _ {k=1}^nX _ k)}}
$$

的分布函数 $F _ {n}(x)$ 对于任意 $x$ 满足

$$
\lim _ {n\to \infty}F _ n(x)=\lim _ {n\to \infty}P\lbrace \frac{\sum _ {k=1}X _ k-n\mu}{\sqrt{n}\sigma} \rbrace
$$

李雅普诺夫定理：设随机变量 $X _ 1,X _ 2,\cdots$ 相互独立，它们具有数学期望和方差

$$
E(X _ k)=\mu _ k,D(X _ k)=\sigma _ k^2>0,k=1,2,\cdots
$$

记

$$
B _ n^2=\sum _ {k=1}^n\sigma _ k^2
$$

若存在正数 $\delta$，使得当 $n\rightarrow \infty$ 时，

$$
\frac{1}{B _ {n}^{2+\delta}}\sum _ {k=1}^nE\lbrace |X _ k-\mu _ k|^{2+\delta} \rbrace \rightarrow 0
$$

则随机变量之和 $\sum _ {k=1}^nX _ k$ 的标准化变量

$$
Z _ n=\dfrac{\sum _ {k=1}^nX _ k-\sum _ {k=1}^n\mu _ k}{B _ n}
$$

的分布函数 $F _ n(x)$ 对于任意 $x$，满足

$$
\lim _ {n\to \infty}F _ n{x}=\lim _ {n\to \infty}=\lim _ {n\to \infty}P\lbrace \dfrac{\sum _ {k=1}^nX _ k-\sum _ {k=1}^n\mu _ k}{B _ n}\leq x \rbrace =\int _ {-\infty}^{x}\dfrac{1}{\sqrt{2\pi}}\mathrm{e}^{-t^2/2}\mathrm{d}t=\varPhi(x)
$$

棣莫弗——拉普拉斯定理：设随机变量 $\eta$ 服从参数为 $n,p(0<p<1)$ 的二项分布，则对于任意 $x$，有

$$
\lim _ {n\to \infty}P\lbrace \dfrac{\eta _ n-np}{\sqrt{np(1-p)}}\leq x \rbrace =\int _ {-\infty}^{x}\dfrac{1}{\sqrt{2\pi}}\mathrm{e}^{-t^2/2}\mathrm{d}t=\varPhi(x)
$$

--------

$$
\mathscr{THE} \quad \mathscr{END}
$$
